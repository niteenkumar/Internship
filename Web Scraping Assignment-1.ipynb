{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Display all the header tags from wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url):\n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    header = soup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "    print('List of all the header tags :', *header, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the header tags :\n",
      "\n",
      "<h1 class=\"central-textlogo-wrapper\">\n",
      "<span class=\"central-textlogo__image sprite svg-Wikipedia_wordmark\">\n",
      "Wikipedia\n",
      "</span>\n",
      "<strong class=\"jsl10n localized-slogan\" data-jsl10n=\"portal.slogan\">The Free Encyclopedia</strong>\n",
      "</h1>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "1 000 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "100 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "10 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "1 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "100+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n"
     ]
    }
   ],
   "source": [
    "scrape(\"https://www.wikipedia.org\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_movie(url):\n",
    "    movies=[]\n",
    "    year = []\n",
    "    ratings=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    \n",
    "    # scrapping movie name\n",
    "    scrapped_movies = soup.find_all('td',class_='titleColumn')\n",
    "    \n",
    "    for movie in scrapped_movies:\n",
    "        movie=movie.get_text().replace('\\n',\"\")\n",
    "        movie=movie.strip(\"\")\n",
    "        movies.append(movie)\n",
    "    \n",
    "    for i in movies:\n",
    "        y=re.findall('\\d+', i )\n",
    "        y=y[-1]\n",
    "        year.append(y)\n",
    "    \n",
    "    # extracting movie name from scrapped data\n",
    "    scrapped_ratings = soup.find_all('td',class_='ratingColumn imdbRating')\n",
    "    \n",
    "    for rating in scrapped_ratings:\n",
    "        rating=rating.get_text().replace('\\n',\"\")\n",
    "        rating=rating.strip(\"\")\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    # creating dataframe\n",
    "    data['Movie Name']=movies[:100]\n",
    "    data['Year']=year[:100]\n",
    "    data['Ratings']=ratings[:100]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      The Shawshank Redemption(1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      The Godfather(1972)</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      The Godfather: Part II(1974)</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      The Dark Knight(2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      12 Angry Men(1957)</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Movie Name  Year Ratings\n",
       "0        1.      The Shawshank Redemption(1994)  1994     9.2\n",
       "1                   2.      The Godfather(1972)  1972     9.1\n",
       "2          3.      The Godfather: Part II(1974)  1974     9.0\n",
       "3                 4.      The Dark Knight(2008)  2008     9.0\n",
       "4                    5.      12 Angry Men(1957)  1957     8.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_movie(\"https://www.imdb.com/chart/top\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Display IMDB’s Top rated 100 Indian movies’ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      Jai Bhim(2021)</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      Nayakan(1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      Pariyerum Perumal(2018)</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      Anbe Sivam(2003)</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      C/o Kancharapalem(2018)</td>\n",
       "      <td>2018</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Movie Name  Year Ratings\n",
       "0                 1.      Jai Bhim(2021)  2021     8.6\n",
       "1                  2.      Nayakan(1987)  1987     8.5\n",
       "2        3.      Pariyerum Perumal(2018)  2018     8.5\n",
       "3               4.      Anbe Sivam(2003)  2003     8.5\n",
       "4        5.      C/o Kancharapalem(2018)  2018     8.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_movie(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.a. Top 10 ODI teams in men’s cricket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_team(url):\n",
    "    teams=[]\n",
    "    match = []\n",
    "    ratings=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    # scrapping team details at position 1\n",
    "    \n",
    "    scrapped_team = soup.find('td',class_='rankings-block__banner--team-name')\n",
    "    team=scrapped_team.get_text().split('\\n')\n",
    "    team=team[2]\n",
    "    teams.append(team)\n",
    "    \n",
    "    scrapped_match = soup.find('td',class_='rankings-block__banner--matches')\n",
    "    mat=scrapped_match.get_text().split('\\n')  \n",
    "    \n",
    "    scrapped_point = soup.find('td',class_='rankings-block__banner--points')\n",
    "    point=scrapped_point.get_text().split('\\n')    \n",
    "    \n",
    "    scrapped_rating = soup.find('td',class_='rankings-block__banner--rating u-text-right')\n",
    "    rating=scrapped_rating.get_text().split()\n",
    "    ratings.append(rating)     \n",
    "    \n",
    "    # scrapping teams details at subsequent positions \n",
    "    \n",
    "    scrapped_team = soup.find_all('td',class_='table-body__cell rankings-table__team')\n",
    "    for team in scrapped_team:\n",
    "        team=team.get_text().split('\\n')\n",
    "        team=team[2]\n",
    "        teams.append(team)\n",
    "        \n",
    "    scrapped_m = soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for m in scrapped_m:\n",
    "        m=m.get_text().split()\n",
    "        match.append(m)\n",
    "        \n",
    "    matches=match[::2]\n",
    "    matches.insert(0,mat)\n",
    "    points=match[1::2]\n",
    "    points.insert(0,point)\n",
    "  \n",
    "    scrapped_rating = soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for rating in scrapped_rating:\n",
    "        rating=rating.get_text().split()\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    # creating dataframe\n",
    "    data['Teams']=teams[:10]\n",
    "    data['Matches']=matches[:10]\n",
    "    data['Points']=points[:10]\n",
    "    data['Ratings']=ratings[:10]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[2,054]</td>\n",
       "      <td>[121]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[3,793]</td>\n",
       "      <td>[119]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>[28]</td>\n",
       "      <td>[3,244]</td>\n",
       "      <td>[116]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[3,624]</td>\n",
       "      <td>[113]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[2,459]</td>\n",
       "      <td>[98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[2,524]</td>\n",
       "      <td>[93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[2,740]</td>\n",
       "      <td>[91]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[2,523]</td>\n",
       "      <td>[84]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[2,657]</td>\n",
       "      <td>[83]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[1,054]</td>\n",
       "      <td>[62]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches   Points Ratings\n",
       "0   New Zealand    [17]  [2,054]   [121]\n",
       "1       England    [32]  [3,793]   [119]\n",
       "2     Australia    [28]  [3,244]   [116]\n",
       "3         India    [32]  [3,624]   [113]\n",
       "4  South Africa    [25]  [2,459]    [98]\n",
       "5      Pakistan    [27]  [2,524]    [93]\n",
       "6    Bangladesh    [30]  [2,740]    [91]\n",
       "7   West Indies    [30]  [2,523]    [84]\n",
       "8     Sri Lanka    [32]  [2,657]    [83]\n",
       "9   Afghanistan    [17]  [1,054]    [62]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_team(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.b. Top 10 ODI Batsmen in men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_batsmen(url):\n",
    "    players=[]\n",
    "    countries = []\n",
    "    ratings=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    # scrapping player name at position 1\n",
    "    \n",
    "    player=soup.find('div',class_='rankings-block__banner--name')\n",
    "    player=player.get_text()\n",
    "    players.append(player)\n",
    "    \n",
    "    a=soup.find('div',class_='rankings-block__banner--nationality')\n",
    "    a=a.get_text().split()\n",
    "    countries.append(a[0])\n",
    "    ratings.append(a[1])\n",
    "        \n",
    "    \n",
    "    # scrapping players at subsequent position \n",
    "    \n",
    "    scrapped_player = soup.find_all('td',class_='table-body__cell name')\n",
    "    for player in scrapped_player:\n",
    "        player=player.get_text().split('\\n')\n",
    "        player=player[1]\n",
    "        players.append(player)\n",
    "        \n",
    "    scrapped_country = soup.find_all('td',class_='table-body__cell nationality-logo')\n",
    "    for country in scrapped_country:\n",
    "        country=country.get_text().split()\n",
    "        countries.append(country)\n",
    "         \n",
    "    scrapped_rating = soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for rating in scrapped_rating:\n",
    "        rating=rating.get_text().split()\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    # creating dataframe\n",
    "    data['Player_Name']=players[:10]\n",
    "    data['Country']=countries[:10]\n",
    "    data['Ratings']=ratings[:10]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[813]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[801]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[779]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>[WI]</td>\n",
       "      <td>[758]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[754]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[743]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Player_Name Country Ratings\n",
       "0       Babar Azam     PAK     873\n",
       "1      Virat Kohli   [IND]   [844]\n",
       "2     Rohit Sharma   [IND]   [813]\n",
       "3      Ross Taylor    [NZ]   [801]\n",
       "4      Aaron Finch   [AUS]   [779]\n",
       "5   Jonny Bairstow   [ENG]   [775]\n",
       "6     David Warner   [AUS]   [762]\n",
       "7        Shai Hope    [WI]   [758]\n",
       "8  Kane Williamson    [NZ]   [754]\n",
       "9  Quinton de Kock    [SA]   [743]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_batsmen(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.c. Top 10 ODI bowlers in men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_bowler(url):\n",
    "    players=[]\n",
    "    countries = []\n",
    "    ratings=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    # # scrapping player name at position 1\n",
    "    a=[]\n",
    "    scrapped_player = soup.find_all('div',class_='rankings-block__banner--name')\n",
    "    for player in scrapped_player:\n",
    "        player=player.get_text().split('\\n')\n",
    "        a.append(player)\n",
    "        \n",
    "    a1=a[1]\n",
    "    \n",
    "    b=[]\n",
    "    a = soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in a:\n",
    "        i=i.get_text().split('\\n')\n",
    "        b.append(i)\n",
    "    b1=b[1][2]\n",
    "    c1=b[1][3]\n",
    "    \n",
    "        \n",
    "    \n",
    "    # scrapping players at subsequent position \n",
    "    \n",
    "    scrapped_player = soup.find_all('td',class_='table-body__cell name')\n",
    "    for player in scrapped_player:\n",
    "        player=player.get_text().split('\\n')\n",
    "        player=player[1]\n",
    "        players.append(player)\n",
    "        \n",
    "    scrapped_country = soup.find_all('td',class_='table-body__cell nationality-logo')\n",
    "    for country in scrapped_country:\n",
    "        country=country.get_text().split()\n",
    "        countries.append(country)\n",
    "         \n",
    "    scrapped_rating = soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for rating in scrapped_rating:\n",
    "        rating=rating.get_text().split()\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    # creating dataframe\n",
    "    players=players[9:18]\n",
    "    players.insert(0,a1)\n",
    "    countries=countries[9:18]\n",
    "    countries.insert(0,b1)\n",
    "    ratings=ratings[9:18]\n",
    "    ratings.insert(0,c1)\n",
    "    data['Player_Name']=players\n",
    "    data['Country']=countries\n",
    "    data['Ratings']=ratings\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Trent Boult]</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[709]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>[AFG]</td>\n",
       "      <td>[708]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[700]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[691]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[679]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>[BAN]</td>\n",
       "      <td>[650]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[643]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Player_Name Country                          Ratings\n",
       "0     [Trent Boult]      NZ                              737\n",
       "1    Josh Hazlewood   [AUS]                            [709]\n",
       "2  Mujeeb Ur Rahman   [AFG]                            [708]\n",
       "3      Chris Woakes   [ENG]                            [700]\n",
       "4      Mehedi Hasan   [BAN]                            [692]\n",
       "5        Matt Henry    [NZ]                            [691]\n",
       "6    Jasprit Bumrah   [IND]                            [679]\n",
       "7    Mitchell Starc   [AUS]                            [652]\n",
       "8   Shakib Al Hasan   [BAN]                            [650]\n",
       "9     Kagiso Rabada    [SA]                            [643]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_bowler(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.a. Top 10 ODI teams in women’s cricket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[2,746]</td>\n",
       "      <td>[162]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[2,307]</td>\n",
       "      <td>[121]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[2,148]</td>\n",
       "      <td>[119]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[1,899]</td>\n",
       "      <td>[112]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[475]</td>\n",
       "      <td>[95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[1,668]</td>\n",
       "      <td>[88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[1,658]</td>\n",
       "      <td>[87]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[1,226]</td>\n",
       "      <td>[68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[240]</td>\n",
       "      <td>[48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[233]</td>\n",
       "      <td>[47]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Teams Matches   Points Ratings\n",
       "0     Australia    [17]  [2,746]   [162]\n",
       "1  South Africa    [19]  [2,307]   [121]\n",
       "2       England    [18]  [2,148]   [119]\n",
       "3         India    [17]  [1,899]   [112]\n",
       "4    Bangladesh     [5]    [475]    [95]\n",
       "5   New Zealand    [19]  [1,668]    [88]\n",
       "6   West Indies    [19]  [1,658]    [87]\n",
       "7      Pakistan    [18]  [1,226]    [68]\n",
       "8       Ireland     [5]    [240]    [48]\n",
       "9     Sri Lanka     [5]    [233]    [47]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_team(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.b Top 10 women’s ODI players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Batsmen in women : \n",
      " --------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[750]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[738]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[728]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>[NZ]</td>\n",
       "      <td>[717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[699]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[690]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>[WI]</td>\n",
       "      <td>[676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Heather Knight</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[674]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Player_Name Country Ratings\n",
       "0        Lizelle Lee      SA     761\n",
       "1       Alyssa Healy   [AUS]   [750]\n",
       "2        Mithali Raj   [IND]   [738]\n",
       "3     Tammy Beaumont   [ENG]   [728]\n",
       "4  Amy Satterthwaite    [NZ]   [717]\n",
       "5    Smriti Mandhana   [IND]   [710]\n",
       "6        Meg Lanning   [AUS]   [699]\n",
       "7        Beth Mooney   [AUS]   [690]\n",
       "8    Stafanie Taylor    [WI]   [676]\n",
       "9     Heather Knight   [ENG]   [674]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_batsmen(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "print(\"Top 10 ODI Batsmen in women : \\n\",\"-\"*32)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Bowler in women : \n",
      " --------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Jess Jonassen]</td>\n",
       "      <td>AUS</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[727]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Megan Schutt</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[715]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[701]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shabnim Ismail</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[688]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[666]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ayabonga Khaka</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[643]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Anya Shrubsole</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[598]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kate Cross</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[589]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Player_Name Country                          Ratings\n",
       "0    [Jess Jonassen]     AUS                              760\n",
       "1     Jhulan Goswami   [IND]                            [727]\n",
       "2       Megan Schutt   [AUS]                            [717]\n",
       "3     Marizanne Kapp    [SA]                            [715]\n",
       "4  Sophie Ecclestone   [ENG]                            [701]\n",
       "5     Shabnim Ismail    [SA]                            [688]\n",
       "6    Katherine Brunt   [ENG]                            [666]\n",
       "7     Ayabonga Khaka    [SA]                            [643]\n",
       "8     Anya Shrubsole   [ENG]                            [598]\n",
       "9         Kate Cross   [ENG]                            [589]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_bowler(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "print(\"Top 10 ODI Bowler in women : \\n\",\"-\"*32)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.c. Top 10 women’s ODI all-rounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_allrounder(url):\n",
    "    players=[]\n",
    "    countries = []\n",
    "    ratings=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    # scrapping player name at position 1\n",
    "    a=[]\n",
    "    scrapped_player = soup.find_all('div',class_='rankings-block__banner--name')\n",
    "    for player in scrapped_player:\n",
    "        player=player.get_text().split('\\n')\n",
    "        a.append(player)\n",
    "        \n",
    "    a1=a[2]\n",
    "    \n",
    "    b=[]\n",
    "    a = soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in a:\n",
    "        i=i.get_text().split('\\n')\n",
    "        b.append(i)\n",
    "    b1=b[2][2]\n",
    "    c1=b[2][3]\n",
    "    \n",
    "        \n",
    "    \n",
    "    # scrapping players at subsequent position \n",
    "    \n",
    "    scrapped_player = soup.find_all('td',class_='table-body__cell name')\n",
    "    for player in scrapped_player:\n",
    "        player=player.get_text().split('\\n')\n",
    "        player=player[1]\n",
    "        players.append(player)\n",
    "        \n",
    "    scrapped_country = soup.find_all('td',class_='table-body__cell nationality-logo')\n",
    "    for country in scrapped_country:\n",
    "        country=country.get_text().split()\n",
    "        countries.append(country)\n",
    "         \n",
    "    scrapped_rating = soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for rating in scrapped_rating:\n",
    "        rating=rating.get_text().split()\n",
    "        ratings.append(rating)\n",
    "    \n",
    "    # creating dataframe\n",
    "    players=players[18:27]\n",
    "    players.insert(0,a1)\n",
    "    countries=countries[18:27]\n",
    "    countries.insert(0,b1)\n",
    "    ratings=ratings[18:27]\n",
    "    ratings.insert(0,c1)\n",
    "    data['Player_Name']=players\n",
    "    data['Country']=countries\n",
    "    data['Ratings']=ratings\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Marizanne Kapp]</td>\n",
       "      <td>SA</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[372]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>[WI]</td>\n",
       "      <td>[319]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>[IND]</td>\n",
       "      <td>[299]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[275]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>[SA]</td>\n",
       "      <td>[274]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>[WI]</td>\n",
       "      <td>[272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>[AUS]</td>\n",
       "      <td>[272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>[ENG]</td>\n",
       "      <td>[272]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Player_Name Country                          Ratings\n",
       "0  [Marizanne Kapp]      SA                              384\n",
       "1    Natalie Sciver   [ENG]                            [372]\n",
       "2      Ellyse Perry   [AUS]                            [365]\n",
       "3   Stafanie Taylor    [WI]                            [319]\n",
       "4     Deepti Sharma   [IND]                            [299]\n",
       "5  Ashleigh Gardner   [AUS]                            [275]\n",
       "6  Dane van Niekerk    [SA]                            [274]\n",
       "7   Hayley Matthews    [WI]                            [272]\n",
       "8     Jess Jonassen   [AUS]                            [272]\n",
       "9   Katherine Brunt   [ENG]                            [272]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrap_allrounder(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Scrape details of all the posts from coreyms.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_post(url):\n",
    "    names=[]\n",
    "    dates=[]\n",
    "    desc = []\n",
    "    links=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    # scrapping heading\n",
    "    scrapped_name = soup.find_all('a',class_='entry-title-link')\n",
    "    for name in scrapped_name:\n",
    "        name=name.get_text()\n",
    "        names.append(name)\n",
    "        \n",
    "    # scrapping date\n",
    "    scrapped_date = soup.find_all('time',class_='entry-time')\n",
    "    for date in scrapped_date:\n",
    "        date=date.get_text()\n",
    "        dates.append(date)\n",
    "        \n",
    "    # scraping content\n",
    "    scrapped_desc = soup.find_all('div',class_='entry-content')\n",
    "    for des in scrapped_desc:\n",
    "        des=des.get_text().split(\"\\n\")\n",
    "        desc.append(des[1])\n",
    "        \n",
    "    # scraping codes\n",
    "    scrapped_link = soup.find_all('iframe',class_='youtube-player')\n",
    "    for link in scrapped_link:\n",
    "        link=str(link).split(\"/\")\n",
    "        link=link[4].split(\"?\")\n",
    "        link=link[0]\n",
    "        links.append(link)\n",
    "    links.insert(4,\"No video for this post\")\n",
    "    \n",
    "    # creating dataframe\n",
    "    data['Heading']=names\n",
    "    data['Date']=dates\n",
    "    data['Content']=desc\n",
    "    data['Unique code']=links\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heading</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Unique code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>November 19, 2019</td>\n",
       "      <td>In this video, we will be learning how to crea...</td>\n",
       "      <td>z0gguhEmWiY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>October 17, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>_P7X8tMplsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>September 21, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>fKl2JW_qrso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>September 12, 2019</td>\n",
       "      <td>In this Python Programming video, we will be l...</td>\n",
       "      <td>IEEhzQoKtQU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>September 3, 2019</td>\n",
       "      <td>Hey everyone. I wanted to give you an update o...</td>\n",
       "      <td>No video for this post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Quick Tip: The Difference Between “==” ...</td>\n",
       "      <td>August 6, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>mO_dS3rXDIs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Tutorial: Calling External Commands Usi...</td>\n",
       "      <td>July 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>2Fp1N6dof0Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visual Studio Code (Windows) – Setting up a Py...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>-nh9rCzPJ20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visual Studio Code (Mac) – Setting up a Python...</td>\n",
       "      <td>May 1, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>06I63_p-2A4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarifying the Issues with Mutable Default Arg...</td>\n",
       "      <td>April 24, 2019</td>\n",
       "      <td>In this Python Programming Tutorial, we will b...</td>\n",
       "      <td>_JGmemuINww</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Heading                Date  \\\n",
       "0  Python Tutorial: Zip Files – Creating and Extr...   November 19, 2019   \n",
       "1  Python Data Science Tutorial: Analyzing the 20...    October 17, 2019   \n",
       "2  Python Multiprocessing Tutorial: Run Code in P...  September 21, 2019   \n",
       "3  Python Threading Tutorial: Run Code Concurrent...  September 12, 2019   \n",
       "4                                Update (2019-09-03)   September 3, 2019   \n",
       "5  Python Quick Tip: The Difference Between “==” ...      August 6, 2019   \n",
       "6  Python Tutorial: Calling External Commands Usi...       July 24, 2019   \n",
       "7  Visual Studio Code (Windows) – Setting up a Py...         May 1, 2019   \n",
       "8  Visual Studio Code (Mac) – Setting up a Python...         May 1, 2019   \n",
       "9  Clarifying the Issues with Mutable Default Arg...      April 24, 2019   \n",
       "\n",
       "                                             Content             Unique code  \n",
       "0  In this video, we will be learning how to crea...             z0gguhEmWiY  \n",
       "1  In this Python Programming video, we will be l...             _P7X8tMplsw  \n",
       "2  In this Python Programming video, we will be l...             fKl2JW_qrso  \n",
       "3  In this Python Programming video, we will be l...             IEEhzQoKtQU  \n",
       "4  Hey everyone. I wanted to give you an update o...  No video for this post  \n",
       "5  In this Python Programming Tutorial, we will b...             mO_dS3rXDIs  \n",
       "6  In this Python Programming Tutorial, we will b...             2Fp1N6dof0Y  \n",
       "7  In this Python Programming Tutorial, we will b...             -nh9rCzPJ20  \n",
       "8  In this Python Programming Tutorial, we will b...             06I63_p-2A4  \n",
       "9  In this Python Programming Tutorial, we will b...             _JGmemuINww  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrape_post(\"https://coreyms.com/\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. House title, location, area, EMI and price from nobroker.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_houses(url):\n",
    "    titles=[]\n",
    "    locations = []\n",
    "    emi=[]\n",
    "    areas=[]\n",
    "    prices=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    # scrapping titles\n",
    "    scrapped_title = soup.find_all('a',class_='nb__U5JyW')\n",
    "    for title in scrapped_title:\n",
    "        title=title.get_text().split()\n",
    "        titles.append(title)\n",
    "    \n",
    "    # scrapping locations\n",
    "    scrapped_location = soup.find_all('div',class_='nb__1EwQz')\n",
    "    for location in scrapped_location:\n",
    "        location=location.get_text().split()\n",
    "        locations.append(location)\n",
    "    \n",
    "    # scrapping area & price\n",
    "    temp=[]\n",
    "    scrapped_detail = soup.find_all('div',class_='font-semi-bold heading-6')\n",
    "    for t in scrapped_detail:\n",
    "        t=t.get_text().split()\n",
    "        temp.append(t)\n",
    "    \n",
    "    # creating dataframe\n",
    "    areas=temp[::3]\n",
    "    emi=temp[1::3]\n",
    "    prices=temp[2::3]\n",
    "    \n",
    "    data['Title']=titles\n",
    "    data['Location']=locations\n",
    "    data['Area']=areas\n",
    "    data['EMI']=emi\n",
    "    data['Price']=prices\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, BHK, In, Independent, House, For, Sale, In...</td>\n",
       "      <td>[Independent, House,, Bangalore, -, Hosur, Roa...</td>\n",
       "      <td>[1,800, sqft]</td>\n",
       "      <td>[₹77,374/Month]</td>\n",
       "      <td>[₹1.35, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, BHK, In, Independent, House, For, Sale, In...</td>\n",
       "      <td>[Independent, House,, brand, factory]</td>\n",
       "      <td>[2,000, sqft]</td>\n",
       "      <td>[₹39,546/Month]</td>\n",
       "      <td>[₹69, Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4, BHK, Flat, For, Sale, In, Electronic, City]</td>\n",
       "      <td>[Standalone, Building,, YOUNG, LIFE, PG, FOR, ...</td>\n",
       "      <td>[1,120, sqft]</td>\n",
       "      <td>[₹28,657/Month]</td>\n",
       "      <td>[₹50, Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4, BHK, Apartment, For, Sale, In, Nisarga, Re...</td>\n",
       "      <td>[Nisarga, Residency, Near, Thali, Resturant,, ...</td>\n",
       "      <td>[2,000, sqft]</td>\n",
       "      <td>[₹45,851/Month]</td>\n",
       "      <td>[₹80, Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4, BHK, Flat, For, Sale, In, Sobha, Silicon, ...</td>\n",
       "      <td>[Sobha, Silicon, Oasis, Naganathapura,, Rayasa...</td>\n",
       "      <td>[1,879, sqft]</td>\n",
       "      <td>[₹91,703/Month]</td>\n",
       "      <td>[₹1.6, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[4, BHK, For, Sale, In, Daadys, Garden, In, El...</td>\n",
       "      <td>[Daadys, Garden, Kammasandra, Rd,, Kammasandra...</td>\n",
       "      <td>[2,600, sqft]</td>\n",
       "      <td>[₹85,971/Month]</td>\n",
       "      <td>[₹1.5, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[4, BHK, Flat, For, Sale, In, ,, Electronic, C...</td>\n",
       "      <td>[Standalone, Building,, 16th, Cross, Road, Nee...</td>\n",
       "      <td>[2,000, sqft]</td>\n",
       "      <td>[₹39,546/Month]</td>\n",
       "      <td>[₹69, Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[4, BHK, Flat, For, Sale, In, Hosa, Road,, Par...</td>\n",
       "      <td>[Standalone, Building,, 11th, cross.anjanadri,...</td>\n",
       "      <td>[3,000, sqft]</td>\n",
       "      <td>[₹71,643/Month]</td>\n",
       "      <td>[₹1.25, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[4, BHK, In, Independent, House, For, Sale, In...</td>\n",
       "      <td>[Independent, House,, surya, nagar, face, 1]</td>\n",
       "      <td>[3,000, sqft]</td>\n",
       "      <td>[₹1.43, Lacs/Month]</td>\n",
       "      <td>[₹2.5, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[4, BHK, In, Independent, House, For, Sale, In...</td>\n",
       "      <td>[Independent, House,, Hosur, Rd,Near, Infosys,...</td>\n",
       "      <td>[1,200, sqft]</td>\n",
       "      <td>[₹42,985/Month]</td>\n",
       "      <td>[₹75, Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[4, BHK, Apartment, For, Sale, In, Gopalan, Ga...</td>\n",
       "      <td>[Gopalan, Gardenia, Gopalan, gardenia,, Veeras...</td>\n",
       "      <td>[2,650, sqft]</td>\n",
       "      <td>[₹68,777/Month]</td>\n",
       "      <td>[₹1.2, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[4, BHK, For, Sale, In, Gpr, Royale, In, Gpr, ...</td>\n",
       "      <td>[6th, Cross]</td>\n",
       "      <td>[3,100, sqft]</td>\n",
       "      <td>[₹85,971/Month]</td>\n",
       "      <td>[₹1.5, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[4, BHK, In, Independent, House, For, Sale, In...</td>\n",
       "      <td>[Independent, House,, Shantipura, Village, ,, ...</td>\n",
       "      <td>[1,100, sqft]</td>\n",
       "      <td>[₹40,120/Month]</td>\n",
       "      <td>[₹70, Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[4, BHK, Flat, For, Sale, In, Heena, Enclave, ...</td>\n",
       "      <td>[Neeladri, Nagar,Near, Pioneer, Sun, Blossom]</td>\n",
       "      <td>[2,350, sqft]</td>\n",
       "      <td>[₹71,643/Month]</td>\n",
       "      <td>[₹1.25, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[4, BHK, For, Sale, In, Deccan, Palms, Park, I...</td>\n",
       "      <td>[Deccan, Palms, Park, Deccan, Palms, Villas,, ...</td>\n",
       "      <td>[3,000, sqft]</td>\n",
       "      <td>[₹85,971/Month]</td>\n",
       "      <td>[₹1.5, Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[4, BHK, In, Independent, House, For, Sale, In...</td>\n",
       "      <td>[Independent, House,, Industrial, Area, Near, ...</td>\n",
       "      <td>[1,500, sqft]</td>\n",
       "      <td>[₹57,314/Month]</td>\n",
       "      <td>[₹1, Crore]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   [4, BHK, In, Independent, House, For, Sale, In...   \n",
       "1   [4, BHK, In, Independent, House, For, Sale, In...   \n",
       "2     [4, BHK, Flat, For, Sale, In, Electronic, City]   \n",
       "3   [4, BHK, Apartment, For, Sale, In, Nisarga, Re...   \n",
       "4   [4, BHK, Flat, For, Sale, In, Sobha, Silicon, ...   \n",
       "5   [4, BHK, For, Sale, In, Daadys, Garden, In, El...   \n",
       "6   [4, BHK, Flat, For, Sale, In, ,, Electronic, C...   \n",
       "7   [4, BHK, Flat, For, Sale, In, Hosa, Road,, Par...   \n",
       "8   [4, BHK, In, Independent, House, For, Sale, In...   \n",
       "9   [4, BHK, In, Independent, House, For, Sale, In...   \n",
       "10  [4, BHK, Apartment, For, Sale, In, Gopalan, Ga...   \n",
       "11  [4, BHK, For, Sale, In, Gpr, Royale, In, Gpr, ...   \n",
       "12  [4, BHK, In, Independent, House, For, Sale, In...   \n",
       "13  [4, BHK, Flat, For, Sale, In, Heena, Enclave, ...   \n",
       "14  [4, BHK, For, Sale, In, Deccan, Palms, Park, I...   \n",
       "15  [4, BHK, In, Independent, House, For, Sale, In...   \n",
       "\n",
       "                                             Location           Area  \\\n",
       "0   [Independent, House,, Bangalore, -, Hosur, Roa...  [1,800, sqft]   \n",
       "1               [Independent, House,, brand, factory]  [2,000, sqft]   \n",
       "2   [Standalone, Building,, YOUNG, LIFE, PG, FOR, ...  [1,120, sqft]   \n",
       "3   [Nisarga, Residency, Near, Thali, Resturant,, ...  [2,000, sqft]   \n",
       "4   [Sobha, Silicon, Oasis, Naganathapura,, Rayasa...  [1,879, sqft]   \n",
       "5   [Daadys, Garden, Kammasandra, Rd,, Kammasandra...  [2,600, sqft]   \n",
       "6   [Standalone, Building,, 16th, Cross, Road, Nee...  [2,000, sqft]   \n",
       "7   [Standalone, Building,, 11th, cross.anjanadri,...  [3,000, sqft]   \n",
       "8        [Independent, House,, surya, nagar, face, 1]  [3,000, sqft]   \n",
       "9   [Independent, House,, Hosur, Rd,Near, Infosys,...  [1,200, sqft]   \n",
       "10  [Gopalan, Gardenia, Gopalan, gardenia,, Veeras...  [2,650, sqft]   \n",
       "11                                       [6th, Cross]  [3,100, sqft]   \n",
       "12  [Independent, House,, Shantipura, Village, ,, ...  [1,100, sqft]   \n",
       "13      [Neeladri, Nagar,Near, Pioneer, Sun, Blossom]  [2,350, sqft]   \n",
       "14  [Deccan, Palms, Park, Deccan, Palms, Villas,, ...  [3,000, sqft]   \n",
       "15  [Independent, House,, Industrial, Area, Near, ...  [1,500, sqft]   \n",
       "\n",
       "                    EMI            Price  \n",
       "0       [₹77,374/Month]  [₹1.35, Crores]  \n",
       "1       [₹39,546/Month]      [₹69, Lacs]  \n",
       "2       [₹28,657/Month]      [₹50, Lacs]  \n",
       "3       [₹45,851/Month]      [₹80, Lacs]  \n",
       "4       [₹91,703/Month]   [₹1.6, Crores]  \n",
       "5       [₹85,971/Month]   [₹1.5, Crores]  \n",
       "6       [₹39,546/Month]      [₹69, Lacs]  \n",
       "7       [₹71,643/Month]  [₹1.25, Crores]  \n",
       "8   [₹1.43, Lacs/Month]   [₹2.5, Crores]  \n",
       "9       [₹42,985/Month]      [₹75, Lacs]  \n",
       "10      [₹68,777/Month]   [₹1.2, Crores]  \n",
       "11      [₹85,971/Month]   [₹1.5, Crores]  \n",
       "12      [₹40,120/Month]      [₹70, Lacs]  \n",
       "13      [₹71,643/Month]  [₹1.25, Crores]  \n",
       "14      [₹85,971/Month]   [₹1.5, Crores]  \n",
       "15      [₹57,314/Month]      [₹1, Crore]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrape_houses(\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44N%20DUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8%20iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. scrape details from dineout.co.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_dining(url):\n",
    "    names=[]\n",
    "    cuisines = []\n",
    "    locations=[]\n",
    "    ratings=[]\n",
    "    links=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "    \n",
    "    # scrapping names\n",
    "    scrapped_name = soup.find_all('a',class_='restnt-name ellipsis')\n",
    "    for name in scrapped_name:\n",
    "        name=name.get_text()\n",
    "        names.append(name)\n",
    "        \n",
    "    # scrapping links\n",
    "    l=[]\n",
    "    scrapped_link = soup.find_all('img',class_='lazy-load-img no-img')\n",
    "    for link in scrapped_link:\n",
    "        l.append(link)\n",
    "        \n",
    "    for i in range(len(l)):\n",
    "        links.append(l[i].attrs['data-src'])\n",
    "\n",
    "    # scrapping ratings\n",
    "    scrapped_rating = soup.find_all('div',class_='restnt-rating rating-4')\n",
    "    for rating in scrapped_rating:\n",
    "        rating=rating.get_text()\n",
    "        ratings.append(rating)\n",
    "\n",
    "    # scrapping cuisines\n",
    "    scrapped_cuisine = soup.find_all('span',class_='double-line-ellipsis')\n",
    "    for cuisine in scrapped_cuisine:\n",
    "        cuisine=cuisine.get_text().split(\"|\")\n",
    "        cuisines.append(cuisine[1])\n",
    "        \n",
    "    # scrapping location\n",
    "    scrapped_location = soup.find_all('div',class_='restnt-loc ellipsis')\n",
    "    for location in scrapped_location:\n",
    "        location=location.get_text()\n",
    "        locations.append(location)\n",
    "    \n",
    "    # creating dataframe\n",
    "    data['Name']=names\n",
    "    data['Locations']=locations\n",
    "    data['Cuisine']=cuisines\n",
    "    data['Rating']=ratings\n",
    "    data['URL']=links\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Rating</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>North Indian, Barbecue, Italian, Asian</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>Multi-Cuisine, North Indian, Italian, Contine...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>Barbecue, Chinese, Mughlai, North Indian</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North Indian, Italian, Oriental</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>Barbecue, North Indian</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>North Indian, Chinese, Fast Food</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World Cafe</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>North Indian, Mughlai, Barbecue</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B Que</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>North Indian, Chinese, Barbecue</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glasshouse</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>Multi-Cuisine, Asian, European, Italian, Nort...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name  \\\n",
       "0                    Castle Barbeque   \n",
       "1                    Jungle Jamboree   \n",
       "2                    Castle Barbeque   \n",
       "3                         Cafe Knosh   \n",
       "4               The Barbeque Company   \n",
       "5                        India Grill   \n",
       "6                     Delhi Barbeque   \n",
       "7   The Monarch - Bar Be Que Village   \n",
       "8                         World Cafe   \n",
       "9                  Indian Grill Room   \n",
       "10                   Mad 4 Bar B Que   \n",
       "11                       Barbeque 29   \n",
       "12                        Glasshouse   \n",
       "\n",
       "                                            Locations  \\\n",
       "0                      Connaught Place, Central Delhi   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi   \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "4                  Gardens Galleria,Sector 38A, Noida   \n",
       "5                Hilton Garden Inn,Saket, South Delhi   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "10                               Sector 29, Faridabad   \n",
       "11                                     NIT, Faridabad   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...   \n",
       "\n",
       "                                              Cuisine Rating  \\\n",
       "0                               Chinese, North Indian    3.5   \n",
       "1              North Indian, Barbecue, Italian, Asian    3.9   \n",
       "2                               North Indian, Chinese      4   \n",
       "3    Multi-Cuisine, North Indian, Italian, Contine...    4.3   \n",
       "4            Barbecue, Chinese, Mughlai, North Indian    4.1   \n",
       "5                    North Indian, Italian, Oriental     3.9   \n",
       "6                              Barbecue, North Indian    3.6   \n",
       "7                    North Indian, Chinese, Fast Food    3.9   \n",
       "8                  North Indian, Chinese, Continental    4.2   \n",
       "9                     North Indian, Mughlai, Barbecue    4.3   \n",
       "10                              North Indian, Mughlai    3.9   \n",
       "11                    North Indian, Chinese, Barbecue    4.2   \n",
       "12   Multi-Cuisine, Asian, European, Italian, Nort...    4.1   \n",
       "\n",
       "                                                  URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrape_dining(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Scrape weather details for last 24 hours from Tutiempo.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='en.tutiempo.net', port=443): Max retries exceeded with url: /delhi.html?data=last-24-hours (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    977\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         self.sock = ssl_wrap_socket(\n\u001b[0m\u001b[0;32m    363\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# ctx._wrap_socket()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         return self.sslsocket_class._create(\n\u001b[0m\u001b[0;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 726\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    727\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='en.tutiempo.net', port=443): Max retries exceeded with url: /delhi.html?data=last-24-hours (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6ad1620ad208>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://en.tutiempo.net/delhi.html?data=last-24-hours\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    528\u001b[0m         }\n\u001b[0;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                 \u001b[1;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='en.tutiempo.net', port=443): Max retries exceeded with url: /delhi.html?data=last-24-hours (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)')))"
     ]
    }
   ],
   "source": [
    "page=requests.get(\"https://en.tutiempo.net/delhi.html?data=last-24-hours\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This link is throwing SSL Certificate Verification Failed Error.\n",
    "# Tried running it quite a many times but it didn't work and according to ticket's resolution, \n",
    "# issue is with website server rejecting the server "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.  Monument name, description, image URL about top 10 monuments from puredestinations.co.uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_monuments(url):\n",
    "    names=[]\n",
    "    desc = []\n",
    "    links=[]\n",
    "    data=pd.DataFrame()\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content)\n",
    "\n",
    "    # scrapping names & description\n",
    "    titles=[]\n",
    "    scrapped_title = soup.find_all('p')\n",
    "    for title in scrapped_title:\n",
    "        title=title.get_text()\n",
    "        titles.append(title)\n",
    "        \n",
    "    names=titles[4::3]\n",
    "    desc=titles[5::3]\n",
    "    names=names[:10]\n",
    "    desc=desc[:10]\n",
    "    \n",
    "    # scrapping links of images\n",
    "    l=[]\n",
    "    scrapped_link = soup.find_all('img')\n",
    "    for link in scrapped_link:\n",
    "        l.append(link)\n",
    "    l=l[6::2]\n",
    "    l=l[:10]\n",
    "    for i in range(len(l)):\n",
    "        a=l[i]\n",
    "        links.append(a.attrs['src'])\n",
    "    \n",
    "    # creating dataframe\n",
    "    data['Name']=names\n",
    "    data['Description']=desc\n",
    "    data['Link']=links\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taj Mahal, Agra</td>\n",
       "      <td>Enlisted in the Seven Wonders of the World, Th...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Golden Temple (Harmandir Sahib), Amritsar</td>\n",
       "      <td>The holiest shrine and pilgrimage place locate...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meenakshi Temple, Madurai</td>\n",
       "      <td>Meenakshi Temple is situated on the Southern b...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mysore Palace, Mysore</td>\n",
       "      <td>The Mysore Palace is a famous historical monum...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gateway of India, Mumbai</td>\n",
       "      <td>Even though Mumbai is famous for its Bollywood...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Red Fort, New Delhi</td>\n",
       "      <td>Declared as the UNESCO’s World Heritage Site, ...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hawa Mahal, Jaipur</td>\n",
       "      <td>Explore a blend of beauty and Rajasthan cultur...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qutub Minar, New Delhi</td>\n",
       "      <td>Discover one of the tallest towers in the worl...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sanchi Stupa, Sanchi</td>\n",
       "      <td>The beautiful and massive dome, Sanchi Stupa a...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Charminar, Hyderabad</td>\n",
       "      <td>No visit to Hyderabad should be complete witho...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name  \\\n",
       "0                             Taj Mahal, Agra   \n",
       "1  Golden Temple (Harmandir Sahib), Amritsar    \n",
       "2                   Meenakshi Temple, Madurai   \n",
       "3                       Mysore Palace, Mysore   \n",
       "4                    Gateway of India, Mumbai   \n",
       "5                         Red Fort, New Delhi   \n",
       "6                          Hawa Mahal, Jaipur   \n",
       "7                      Qutub Minar, New Delhi   \n",
       "8                        Sanchi Stupa, Sanchi   \n",
       "9                        Charminar, Hyderabad   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Enlisted in the Seven Wonders of the World, Th...   \n",
       "1  The holiest shrine and pilgrimage place locate...   \n",
       "2  Meenakshi Temple is situated on the Southern b...   \n",
       "3  The Mysore Palace is a famous historical monum...   \n",
       "4  Even though Mumbai is famous for its Bollywood...   \n",
       "5  Declared as the UNESCO’s World Heritage Site, ...   \n",
       "6  Explore a blend of beauty and Rajasthan cultur...   \n",
       "7  Discover one of the tallest towers in the worl...   \n",
       "8  The beautiful and massive dome, Sanchi Stupa a...   \n",
       "9  No visit to Hyderabad should be complete witho...   \n",
       "\n",
       "                                                Link  \n",
       "0  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "1  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "2  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "3  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "4  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "5  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "6  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "7  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "8  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "9  http://www.puredestinations.co.uk/wp-content/u...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=scrape_monuments(\"https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
